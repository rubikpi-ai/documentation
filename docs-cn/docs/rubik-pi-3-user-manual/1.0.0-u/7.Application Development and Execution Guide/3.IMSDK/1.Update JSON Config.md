# 配置示例应用程序

本节提供了一个灵活的工作流程，描述如何使用 Ubuntu 上的 Qualcomm® 智能多媒体产品 (QIMP) SDK 运行和定制高级多媒体和 AI 示例应用程序。开发人员可以使用 JSON 配置文件定义输入/输出源、运行时目标和模型精度，从而实现跨 CPU、GPU 和 DSP 的无缝评估。该方案支持 TFLite、QNN 和 SNPE 等框架并与 AI Hub 集成，非常适合构建和优化针对特定用例的边缘 AI 管道。

使用 **QIMP SDK** 运行高级多媒体和 AI 示例应用程序，开发人员可以：

- 跨异构计算目标（CPU、GPU、DSP）对**AI 工作负载进行原型设计和验证**，帮助团队为其用例选择最高效的运行时。
- 使用基于 JSON 的配置**自定义应用程序行为**，从而可以精确控制输入/输出源、模型类型和运行时参数。
- 利用 AI Hub 的预集成模型和 TFLite、QNN、SNPE 等支持的框架来**加速开发和部署**
- **对性能进行基准测试并优化资源使用**，对于计算和功率预算有限的嵌入式系统和边缘设备至关重要。
- 对模型、标签及媒体资源采用标准化的脚本与目录结构，由此确保跨高通平台的**兼容性与可复现性**。

**前提条件**

* **Ubuntu 操作系统** 已刷入。
* 具有适当权限的**终端访问**。
* 基本熟悉**JSON 配置文件** 和运行时环境变量。
* **访问 AI Hub** 进行模型选择和导出。[**创建 AI Hub** **账户**](https://aihub.qualcomm.com/)
* 如果您之前没有安装过 PPA 包，请按照以下步骤进行安装。
  ```shell
    git clone -b ubuntu_setup --single-branch https://github.com/rubikpi-ai/rubikpi-script.git 
    cd rubikpi-script  
    ./install_ppa_pkgs.sh 
  ```

## 使用以下步骤配置脚本并运行模型

1️⃣ 下载并运行脚本。此脚本将自动获取运行示例应用程序所需的所有包，包括：

- 模型
- 标签
- 媒体文件

```shell
cd /home/ubuntu 
curl -L -O https://raw.githubusercontent.com/quic/sample-apps-for-qualcomm-linux/refs/heads/main/download_artifacts.sh
sudo chmod +x download_artifacts.sh 
sudo ./download_artifacts.sh -v GA1.5-rel -c QCS6490
```

---


#### 说明

- 使用`-v`参数来定义您想要使用的**版本**（例如，GA1.5-rel）。
- 使用`-c`参数来定义您的设备正在使用的**芯片组**（例如，QCS6490）。

2️⃣验证模型/标签/媒体文件  
在启动任何示例应用程序之前，请确保所需文件已到位。

#### 检查以下目录：

- **模型文件**→  `/etc/models/`
- **标签文件**→  `/etc/labels/`
- **媒体文件**→  `/etc/media/`

:::note 
这些文件对于 AI 示例应用程序的正常运行至关重要。如果缺失，请重新运行构建产物下载脚本。
:::

3️⃣ 更新 JSON 配置文件  
要运行具有特定功能的示例应用程序，需要一个正确配置的 JSON 文件。

#### 所需操作

- 根据您的**模型**和**配置要求**更新所需的JSON配置文件。
- 更新`e.g. - /etc/configs/config_classification.json`处的文件以匹配您的用例：

#### 配置参数

<details>
更新您的 JSON 配置文件，添加以下关键参数：
- **输入源**  
  - Camera  
  - File (Filesrc)  
  - RTSP Stream  
- **输出源**  
  - Waylandsink  
  - Filesink  
  - RTSP Stream  
- **运行时选项**  
  - CPU  
  - GPU  
  - DSP  
- **精度**  
  - INT8 / INT16  
  - W8A8 / W8A16  
  - FP32  
- **模型类型**  
  - 从**AI Hub**选择可用模型  
- **标签**
  - 选择正确的标签文件 
</details>
## 示例应用程序配置矩阵

| 示例应用程序名称| 详情| AI Hub 模型类型| 运行时| 使用的脚本
|----------|----------|----------|----------|----------
| gst-ai-classification| [图像分类](https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/gst-ai-classification.html)| MobileNet-v2, ResNet101, GoogLeNet, MobileNet-v3-Large, ResNet18, ResNeXt50, ResNeXt101, SqueezeNet, WideResNet50, Shufflenet| CPU, GPU, DSP| [更新 JSON](https://git.codelinaro.org/clo/le/platform/vendor/qcom-opensource/gst-plugins-qti-oss/-/blob/imsdk.lnx.2.0.0.r2-rel/gst-sample-apps/gst-ai-classification/config_classification.json?ref_type=heads)
| gst-ai-object-detection| [目标检测](https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/gst-ai-object-detection.html)| Yolox, Yolov7, Yolov8-Detection (手动导出)| CPU, GPU, DSP| 从 AI Hub 导出模型；更新 Yolox/Yolov7 脚本 – [更新JSON](https://git.codelinaro.org/clo/le/platform/vendor/qcom-opensource/gst-plugins-qti-oss/-/blob/imsdk.lnx.2.0.0.r2-rel/gst-sample-apps/gst-ai-classification/config_classification.json?ref_type=heads)
| gst-ai-pose-detection| [姿态检测](https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/gst-ai-pose-detection.html)| hrnet\_pose| CPU, GPU, DSP| TFLite 默认运行；更新精度/运行时脚本 – [更新 JSON](https://git.codelinaro.org/clo/le/platform/vendor/qcom-opensource/gst-plugins-qti-oss/-/blob/imsdk.lnx.2.0.0.r2-rel/gst-sample-apps/gst-ai-classification/config_classification.json?ref_type=heads)
| gst-ai-segmentation| [图像分割](https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/gst-ai-segmentation.html)| FFNet-40S, FFNet-54S, FFNet-78S| CPU, GPU, DSP| [更新 JSON](https://git.codelinaro.org/clo/le/platform/vendor/qcom-opensource/gst-plugins-qti-oss/-/blob/imsdk.lnx.2.0.0.r2-rel/gst-sample-apps/gst-ai-classification/config_classification.json?ref_type=heads)
| gst-ai-superresolution| [视频超分辨率](https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/video-super-resolution.html)| quicksrnetsmall, QuickSRNetMedium, QuickSRNetLarge, XLSR| CPU, GPU, DSP| [更新 JSON](https://git.codelinaro.org/clo/le/platform/vendor/qcom-opensource/gst-plugins-qti-oss/-/blob/imsdk.lnx.2.0.0.r2-rel/gst-sample-apps/gst-ai-classification/config_classification.json?ref_type=heads)
| gst-ai-multistream-batch-inference| [多流批量推理](https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/multistream-batch-inference.html)| YoloV8-Detection (批大小为 4), DeeplabV3 (批大小为 4)| CPU, GPU, DSP| 从 AI Hub 导出模型；更新脚本 – [更新 JSON](https://git.codelinaro.org/clo/le/platform/vendor/qcom-opensource/gst-plugins-qti-oss/-/blob/imsdk.lnx.2.0.0.r2-rel/gst-sample-apps/gst-ai-classification/config_classification.json?ref_type=heads)
| gst-ai-face-detection| [人脸检测](https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/gst-ai-face-detection.html)| face\_det\_lite| CPU, GPU, DSP| [更新 JSON](https://git.codelinaro.org/clo/le/platform/vendor/qcom-opensource/gst-plugins-qti-oss/-/blob/imsdk.lnx.2.0.0.r2-rel/gst-sample-apps/gst-ai-classification/config_classification.json?ref_type=heads)
| gst-ai-face-recognition| [人脸识别](https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/gst-ai-face-recognition.html)| face\_det\_lite, face\_attrib\_net, facemap\_3dmm| CPU, GPU, DSP| 需要进行人脸注册；否则输出为“识别出未知人脸”
| gst-ai-metadata-parser-example| [元数据解析](https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/gst-ai-metadata-parser.html)| Yolov8-Detection| CPU, GPU, DSP| 从 AI Hub 导出模型
| gst-ai-usb-camera-app| [AI USB 摄像头](https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/gst-ai-metadata-parser.html)| Yolov8-Detection| CPU, GPU, DSP| 从 AI Hub 导出模型
| gst-ai-parallel-inference| [并行推理](https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/gst-ai-parallel-inference.html)| Yolov8-Detection, Deeplab, Hrnet, Inceptionv3| CPU, GPU, DSP| 从 AI Hub 导出模型；为其他模型 [更新 JSON](https://git.codelinaro.org/clo/le/platform/vendor/qcom-opensource/gst-plugins-qti-oss/-/blob/imsdk.lnx.2.0.0.r2-rel/gst-sample-apps/gst-ai-classification/config_classification.json?ref_type=heads)
| gst-ai-daisychain-detection-classification| [菊花链检测与分类](https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/daisy-chain-detection-and-classification.html)| Inceptionv3 + YoloV8| CPU, GPU, DSP| 从 AI Hub 导出模型；为其他模型 [更新 JSON](https://git.codelinaro.org/clo/le/platform/vendor/qcom-opensource/gst-plugins-qti-oss/-/blob/imsdk.lnx.2.0.0.r2-rel/gst-sample-apps/gst-ai-classification/config_classification.json?ref_type=heads)
| gst-ai-audio-classification| [音频分类](https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/audio-classification.html)| Inceptionv3 + YoloV8| CPU, GPU, DSP| 从 AI Hub 导出模型；为其他模型 [更新 JSON](https://git.codelinaro.org/clo/le/platform/vendor/qcom-opensource/gst-plugins-qti-oss/-/blob/imsdk.lnx.2.0.0.r2-rel/gst-sample-apps/gst-ai-classification/config_classification.json?ref_type=heads)
| gst-ai-smartcodec-example| [AI 智能 codec](https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/ai-smart-codec.html)| Inceptionv3 + YoloV8| CPU, GPU, DSP| 从 AI Hub 导出模型；为其他模型 [更新 JSON](https://git.codelinaro.org/clo/le/platform/vendor/qcom-opensource/gst-plugins-qti-oss/-/blob/imsdk.lnx.2.0.0.r2-rel/gst-sample-apps/gst-ai-classification/config_classification.json?ref_type=heads)

使用 SSH 或 SBC 终端启动示例应用程序。
:::note 
如果终端处于root状态，则需要设置以下环境。但对于 ubuntu 用户来说无需此操作。
 
`export XDG\_RUNTIME\_DIR=/run/user/$(id -u ubuntu)`
:::

#### 示例

对于 AI 分类示例应用程序，打开 */etc/configs/config\_classification.json* 配置文件并更新默认标签文件。  
将  
"labels": "/etc/labels/classification.labels"  
改为  
"labels": "/etc/labels/imagenet\_labels.txt"

运行 AI 分类示例应用程序。

```shell
gst-ai-classification
```

要显示可用的帮助选项，请在 SSH shell 中运行以下命令：

```bash
gst-ai-classification -h
```

按**CTRL + C**可停止用例。

### 参考文档：

要进一步探索示例应用程序，请参阅 Qualcomm Intelligent Multimedia SDK (IM SDK) 参考。[Qualcomm Intelligent Multimedia SDK (IM SDK) Reference](https://docs.qualcomm.com/bundle/publicresource/topics/80-70020-50/example-applications.html)